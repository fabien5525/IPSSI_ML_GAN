{"cells":[{"cell_type":"markdown","metadata":{"id":"sIftcvAWeekQ"},"source":["## **GAN is short form of Generative Adversarial Network** and a deep learning architecture. GAN consists of 2 parts, Discriminator and Generator.\n","The Generator tries to creat fake images and fool the Discriminator, and Discriminator tries to distinguish the images and label them as fake(0) or real(1).\n","\n","\n","This zero-sum game continuees until the Generator can no longer creat images which fools the Discriminator and the Discriminator cannot be fooled.\n","\n","\n","There are different types of GAN Models but we are using DCGAN which is the short form of Deep Convolutional GAN."]},{"cell_type":"markdown","metadata":{"id":"WuSFhzJqBjm-"},"source":["## Step 1 | Importing libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:45:50.113310Z","iopub.status.busy":"2023-10-23T10:45:50.112319Z","iopub.status.idle":"2023-10-23T10:45:50.120868Z","shell.execute_reply":"2023-10-23T10:45:50.119912Z","shell.execute_reply.started":"2023-10-23T10:45:50.113259Z"},"id":"UBtseytH_i5A","trusted":true},"outputs":[],"source":["# tensorflow and keras\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n","from tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D, Dropout, Reshape, Conv2DTranspose\n","from tensorflow.keras.models import Sequential\n","import pathlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.optimizers import Adam\n","import os\n","import PIL\n","import time\n","from IPython import display\n","\n","BinaryCrossentropy = tf.keras.metrics.BinaryCrossentropy()\n"]},{"cell_type":"markdown","metadata":{"id":"pDtRhyc_D92E"},"source":["# Step 2 | Preparing data and showing some images"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:45:55.051859Z","iopub.status.busy":"2023-10-23T10:45:55.051095Z","iopub.status.idle":"2023-10-23T10:45:55.056166Z","shell.execute_reply":"2023-10-23T10:45:55.055100Z","shell.execute_reply.started":"2023-10-23T10:45:55.051824Z"},"id":"8qOMllpv_i7k","trusted":true},"outputs":[],"source":["# absolute path : /tf/notebooks/data\n","root_path = pathlib.Path('/tf/notebooks/data')\n","\n","print(root_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:45:57.683316Z","iopub.status.busy":"2023-10-23T10:45:57.682560Z","iopub.status.idle":"2023-10-23T10:48:20.416683Z","shell.execute_reply":"2023-10-23T10:48:20.415625Z","shell.execute_reply.started":"2023-10-23T10:45:57.683262Z"},"id":"lS12O-iEsjDp","outputId":"b964f48f-12e9-41c1-a020-8262a5028a57","trusted":true},"outputs":[],"source":["# prepraing data\n","batch_size = 32\n","\n","data = keras.utils.image_dataset_from_directory(\n","    directory=root_path,\n","    label_mode=None,\n","    batch_size=batch_size,\n","    image_size=(150,100))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:48:22.483810Z","iopub.status.busy":"2023-10-23T10:48:22.483427Z","iopub.status.idle":"2023-10-23T10:48:22.491189Z","shell.execute_reply":"2023-10-23T10:48:22.490238Z","shell.execute_reply.started":"2023-10-23T10:48:22.483776Z"},"id":"_z3fjAsMZV3Q","outputId":"480ab234-5775-4740-b1c1-5e47d387282e","trusted":true},"outputs":[],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:48:41.782662Z","iopub.status.busy":"2023-10-23T10:48:41.782255Z","iopub.status.idle":"2023-10-23T10:48:43.176161Z","shell.execute_reply":"2023-10-23T10:48:43.175105Z","shell.execute_reply.started":"2023-10-23T10:48:41.782632Z"},"id":"3K41P1uW7Iea","outputId":"14b2d451-13f9-411a-fbc6-d60f14edbf9a","trusted":true},"outputs":[],"source":["# let's see some images of the dataset (100x150px)\n","plt.figure(figsize=(5,5))\n","for images in data.take(1):\n","    for i in range(16):\n","        ax = plt.subplot(4, 4, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"))\n","        plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:48:46.692084Z","iopub.status.busy":"2023-10-23T10:48:46.691052Z","iopub.status.idle":"2023-10-23T10:48:46.724486Z","shell.execute_reply":"2023-10-23T10:48:46.723547Z","shell.execute_reply.started":"2023-10-23T10:48:46.692047Z"},"id":"ECVLTEZISn3Y","outputId":"b69268f2-cf2a-4306-ea2e-8e6be00ac855","trusted":true},"outputs":[],"source":["# normalizing the input image to the range [-1, 1]\n","data = data.map(lambda d : ((d-127.5)/127.5))\n","data"]},{"cell_type":"markdown","metadata":{"id":"PbG-3JpwjXVH"},"source":["# Step 3 | Building Discriminator"]},{"cell_type":"markdown","metadata":{"id":"x-bQXkzZq6V9"},"source":["**What is Discriminator ?**\n","\n","The Discriminator is a Neural Network model which tries to distinguish the real images from fake images(generated by Generator) and label them as fake(0) or real(1)."]},{"cell_type":"markdown","metadata":{"id":"79tEezGCq6Yl"},"source":["**Notes** :\n","\n","1.The image size is (150,100), so the input_shape of first conv2d layer should be (150,100,3).\n","\n","2.The output of Discriminator is either a 0(fake) or 1(real).\n","\n","3.Using \"same\" as padding ensures us that the output dimension is not going to change.\n","\n","\n","4.In the Discriminator function, all activations should be \"LeakyReLU\", exept the last layer which should be \"sigmoid\"\n","\n","\n","5.The last layer is using \"sigmoid\" as activation function to create a binary output, which real images are labeled as 1 and the fake ones are labeled as 0.\n","\n","\n","6. The Discriminator downsamples the input shape."]},{"cell_type":"markdown","metadata":{"id":"RLgsMw40LYKo"},"source":["First let's build Discriminator function"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:48:54.294219Z","iopub.status.busy":"2023-10-23T10:48:54.293941Z","iopub.status.idle":"2023-10-23T10:48:54.607762Z","shell.execute_reply":"2023-10-23T10:48:54.606874Z","shell.execute_reply.started":"2023-10-23T10:48:54.294194Z"},"id":"Snu5ati6Iiup","outputId":"f0ee9a3c-0e0e-4ad7-9550-c81551006004","trusted":true},"outputs":[],"source":["# Discriminator\n","def Discriminator():\n","  discriminator = Sequential()\n","  discriminator.add(Conv2D(filters=64, kernel_size=3, strides=(1,1), padding=\"same\", activation=\"LeakyReLU\", input_shape=(150,100,3)))\n","  discriminator.add(BatchNormalization())\n","  discriminator.add(Dropout(0.2))\n","\n","  discriminator.add(Conv2D(filters=128, kernel_size=3, strides=(5,5), padding=\"same\", activation=\"LeakyReLU\"))\n","  discriminator.add(BatchNormalization())\n","  discriminator.add(Dropout(0.2))\n","\n","  discriminator.add(Conv2D(filters=256, kernel_size=3, strides=(5,5), padding=\"same\", activation=\"LeakyReLU\"))\n","  discriminator.add(BatchNormalization())\n","  discriminator.add(Dropout(0.2))\n","\n","  discriminator.add(Conv2D(filters=256, kernel_size=3, strides=(2,2), padding=\"same\", activation=\"LeakyReLU\"))\n","  discriminator.add(BatchNormalization())\n","  discriminator.add(Dropout(0.2))\n","\n","  discriminator.add(Flatten())\n","  discriminator.add(Dropout(0.2))\n","  discriminator.add(Dense(units=1, activation=\"sigmoid\"))\n","\n","  return discriminator\n","\n","D_model = Discriminator()\n","D_model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:48:59.154016Z","iopub.status.busy":"2023-10-23T10:48:59.153125Z","iopub.status.idle":"2023-10-23T10:48:59.159855Z","shell.execute_reply":"2023-10-23T10:48:59.158933Z","shell.execute_reply.started":"2023-10-23T10:48:59.153981Z"},"id":"ucA9CPRGo0f-","trusted":true},"outputs":[],"source":["# optimizer\n","D_optm = Adam(1e-4)"]},{"cell_type":"markdown","metadata":{"id":"qY7tnGWJcuqu"},"source":["# Step 4 | Building Generator"]},{"cell_type":"markdown","metadata":{"id":"oFB8V3Wcc3ok"},"source":["**What is Generator ?**\n","\n","The Generator tries to creat fake images and fool the Discriminator, and Discriminator tries to distinguish the images and label them as fake(0) or real(1)."]},{"cell_type":"markdown","metadata":{"id":"M2NcODSEv95H"},"source":["**Notes :**\n","\n","1.The latent space is an arbitrarily defined vector space of Gaussian-distributed\n","values and here I consider 100 as latent_dim.\n","\n","2.Also units in Dense layer can be (4,4,256) (so it has 4096 nodes)---> 256 versions of 4*4 images.\n","\n","3.Using \"same\" as padding ensures us that the output dimension is not going to change.\n","\n","4.The output shape will be (None, 64, 64, 3) just like the input image(real image) of Discriminator.\n","\n","5. In Generator, we can use Upsampling or Conv2DTranspose layer to upsample the input."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:49:03.463909Z","iopub.status.busy":"2023-10-23T10:49:03.463549Z","iopub.status.idle":"2023-10-23T10:49:03.644314Z","shell.execute_reply":"2023-10-23T10:49:03.643485Z","shell.execute_reply.started":"2023-10-23T10:49:03.463881Z"},"id":"WRmTYdibc4Vz","outputId":"0c48cff6-7a08-4ff1-afc8-c1402e2af79e","trusted":true},"outputs":[],"source":["latent_dim = 100\n","\n","# Build the Generator function\n","def Generator():\n","  generator = Sequential()\n","  generator.add(Dense(units=3*2*256, input_shape =[latent_dim], use_bias=False))\n","  generator.add(Reshape((3,2,256)))\n","  generator.add(BatchNormalization())\n","\n","\n","  generator.add(Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(5, 5), padding =\"same\", activation =\"ReLU\"))\n","  generator.add(BatchNormalization())\n","  \n","  generator.add(Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=(5, 5), padding =\"same\", activation =\"ReLU\"))\n","  generator.add(BatchNormalization())\n","\n","  generator.add(Conv2DTranspose(filters=3, kernel_size=(3, 3), strides=(2, 2), padding=\"same\", activation=\"tanh\"))\n","  \n","  return generator\n","\n","# optimizer\n","G_optm = Adam(1e-4)\n","\n","# a summary of the Generetor\n","G_model = Generator()\n","G_model.summary()"]},{"cell_type":"markdown","metadata":{"id":"P1z00J_ejYZX"},"source":["# Step 5 | Checking if G and D works"]},{"cell_type":"markdown","metadata":{},"source":["Let's see how each model work befor training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:49:18.373106Z","iopub.status.busy":"2023-10-23T10:49:18.372574Z","iopub.status.idle":"2023-10-23T10:49:18.492782Z","shell.execute_reply":"2023-10-23T10:49:18.491290Z","shell.execute_reply.started":"2023-10-23T10:49:18.373061Z"},"id":"8_Hxpk9N1bTy","outputId":"e7ee1996-f062-4bb1-8313-bc777880dff6","trusted":true},"outputs":[],"source":["# creating random noise\n","random_noise = tf.random.normal([1,latent_dim])\n","\n","# feeding random noise to Genereator\n","G_output_on_random_noise = G_model(random_noise, training=False)\n","\n","print(G_output_on_random_noise.shape)\n","\n","# showing the image output of G_model\n","plt.imshow(G_output_on_random_noise[0, :, :, 0])\n","plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:49:20.934078Z","iopub.status.busy":"2023-10-23T10:49:20.933197Z","iopub.status.idle":"2023-10-23T10:49:21.190989Z","shell.execute_reply":"2023-10-23T10:49:21.190040Z","shell.execute_reply.started":"2023-10-23T10:49:20.934046Z"},"id":"rxWKz1j6j_Ig","outputId":"67df4f91-4903-49df-a070-dac61144e4d0","trusted":true},"outputs":[],"source":["# feeding the output of Generator to Discriminator\n","D_output_on_random_noise = D_model(G_output_on_random_noise)\n","print(D_output_on_random_noise)"]},{"cell_type":"markdown","metadata":{"id":"rj6JNA2khWiy"},"source":["# Step 6 | Training loop"]},{"cell_type":"markdown","metadata":{},"source":["The training function in DCGAN (Deep Convolutional Generative Adversarial Network) is responsible for training the generator and discriminator networks simultaneously. The goal of this training process is to optimize the generator and discriminator models so that the generator can generate realistic images, while the discriminator can accurately distinguish between real and generated images."]},{"cell_type":"markdown","metadata":{},"source":["**The training process in DCGAN involves two main steps:**\n","\n","1. Training the Discriminator:\n","   - The discriminator network is trained first using a batch of real images from the dataset and a batch of generated images from the generator.\n","   - The discriminator assigns probabilities to each image, indicating whether it believes the image is real or generated.\n","   - The loss function for the discriminator is calculated based on how well it classifies real and generated images. The goal is to minimize this loss function.\n","   - The gradients of the loss function with respect to the discriminator's parameters are computed using backpropagation, and then used to update the discriminator's weights.\n","\n","2. Training the Generator:\n","   - After updating the discriminator, we train the generator network.\n","   - The generator takes random noise as input and generates fake images.\n","   - These generated images are then fed into the updated discriminator.\n","   - The loss function for the generator is calculated based on how well it fools the discriminator into classifying its generated images as real.\n","   - Similar to before, gradients of this loss function with respect to generator's parameters are computed using backpropagation, and then used to update its weights."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:51:00.525534Z","iopub.status.busy":"2023-10-23T10:51:00.525126Z","iopub.status.idle":"2023-10-23T10:51:00.543182Z","shell.execute_reply":"2023-10-23T10:51:00.542258Z","shell.execute_reply.started":"2023-10-23T10:51:00.525506Z"},"id":"KDy56wLli4ay","trusted":true},"outputs":[],"source":["# The code of this cell is from keras sample.\n","class GAN(tf.keras.Model):\n","    def __init__(self, discriminator, generator, latent_dim):\n","        super(GAN, self).__init__()\n","        self.discriminator = discriminator\n","        self.generator = generator\n","        self.latent_dim = latent_dim\n","\n","    def compile(self, d_optimizer, g_optimizer, loss_fn):\n","        super(GAN, self).compile()\n","        self.d_optimizer = d_optimizer\n","        self.g_optimizer = g_optimizer\n","        self.loss_fn = loss_fn\n","        self.d_loss_metric = tf.keras.metrics.Mean(name=\"d_loss\")\n","        self.g_loss_metric = tf.keras.metrics.Mean(name=\"g_loss\")\n","\n","    @property\n","    def metrics(self):\n","        return [self.d_loss_metric, self.g_loss_metric]\n","\n","    def train_step(self, real_images):\n","        # Sample random points in the latent space\n","        batch_size = tf.shape(real_images)[0]\n","        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n","        # Decode them to fake images\n","        generated_images = self.generator(seed)\n","        # Combine them with real images\n","        combined_images = tf.concat([generated_images, real_images], axis=0)\n","        # Assemble labels discriminating real from fake images\n","        labels = tf.concat([tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0)\n","        # Add random noise to the labels - important trick!\n","        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n","        # Train the discriminator\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(combined_images)\n","            d_loss = self.loss_fn(labels, predictions)\n","        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n","        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n","\n","        # Sample random points in the latent space\n","        seed = tf.random.normal(shape=(batch_size, self.latent_dim))\n","\n","        # Assemble labels that say \"all real images\"\n","        misleading_labels = tf.zeros((batch_size, 1))\n","\n","        # Train the generator (note that we should *not* update the weights of the discriminator)!\n","        with tf.GradientTape() as tape:\n","            predictions = self.discriminator(self.generator(seed))\n","            g_loss = self.loss_fn(misleading_labels, predictions)\n","        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n","        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n","\n","        # Update metrics\n","        self.d_loss_metric.update_state(d_loss)\n","        self.g_loss_metric.update_state(g_loss)\n","        return {\"d_loss\": self.d_loss_metric.result(), \"g_loss\": self.g_loss_metric.result()}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:51:04.032510Z","iopub.status.busy":"2023-10-23T10:51:04.031804Z","iopub.status.idle":"2023-10-23T10:51:04.036730Z","shell.execute_reply":"2023-10-23T10:51:04.035779Z","shell.execute_reply.started":"2023-10-23T10:51:04.032476Z"},"id":"AuzZy3m6VQ6x","trusted":true},"outputs":[],"source":["# loss function\n","loss_fn = tf.keras.losses.BinaryCrossentropy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:51:13.661961Z","iopub.status.busy":"2023-10-23T10:51:13.661614Z","iopub.status.idle":"2023-10-23T10:51:13.671615Z","shell.execute_reply":"2023-10-23T10:51:13.670677Z","shell.execute_reply.started":"2023-10-23T10:51:13.661936Z"},"id":"ziv-Jy2mVdzb","trusted":true},"outputs":[],"source":["# Defining GAN model\n","model = GAN(discriminator=D_model, generator=G_model, latent_dim=latent_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:51:16.665818Z","iopub.status.busy":"2023-10-23T10:51:16.664845Z","iopub.status.idle":"2023-10-23T10:51:16.690499Z","shell.execute_reply":"2023-10-23T10:51:16.689518Z","shell.execute_reply.started":"2023-10-23T10:51:16.665783Z"},"id":"AeTx4S_WVdwm","trusted":true},"outputs":[],"source":["# Compiling GAN Model\n","model.compile(d_optimizer=D_optm, g_optimizer=G_optm, loss_fn=loss_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(tf.config.list_physical_devices('GPU'))\n","\n","if tf.config.list_physical_devices('GPU'):\n","    print(\"GPU is available.\")\n","else:\n","    print(\"GPU is NOT available.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T10:54:34.994178Z","iopub.status.busy":"2023-10-23T10:54:34.993768Z","iopub.status.idle":"2023-10-23T11:20:17.607522Z","shell.execute_reply":"2023-10-23T11:20:17.606709Z","shell.execute_reply.started":"2023-10-23T10:54:34.994145Z"},"id":"mfgFbb3bmAM6","outputId":"325bfe11-fc2e-4e8a-94d4-9481c533e5ad","trusted":true},"outputs":[],"source":["# number of epochs\n","epochs = 10\n","# Fitting the GAN model\n","history = model.fit(data, epochs=epochs)"]},{"cell_type":"markdown","metadata":{"id":"TEjftEsA0ZjB"},"source":["# Step 7 | Using the trained Generated to creat new images"]},{"cell_type":"markdown","metadata":{},"source":["Now we can use the trained Generator to creat new images. Let's show some images generated from the trained Generator."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-23T11:20:23.208172Z","iopub.status.busy":"2023-10-23T11:20:23.207484Z","iopub.status.idle":"2023-10-23T11:20:23.213158Z","shell.execute_reply":"2023-10-23T11:20:23.212219Z","shell.execute_reply.started":"2023-10-23T11:20:23.208136Z"},"trusted":true},"outputs":[],"source":["# creating a random nosie to feed it to the trained Generator model\n","noise = tf.random.normal([32, 100])\n","# Generatine new images using the trained Generator model \n","generated_images = G_model(noise, training=False)\n","\n","# converting the input image to the range [0, 255]\n","generated_images1 = (generated_images+127.5)*127.5\n","\n","plt.figure(figsize=(8, 5))\n","for i in range(16):\n","    ax = plt.subplot(4, 4, i+1)\n","    plt.imshow(generated_images1[i].numpy().astype(\"uint8\"))\n","    plt.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["This images are generated from the trained generator with 35 epochs. In order to have better images you can train the GAN_model with more epochs."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0rc1"}},"nbformat":4,"nbformat_minor":4}
